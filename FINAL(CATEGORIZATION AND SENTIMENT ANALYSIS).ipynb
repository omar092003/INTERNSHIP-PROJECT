{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0b27ee-c862-4320-a36a-211a8c2974e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2', '3': 'LABEL_3', '4': 'LABEL_4', '5': 'LABEL_5', '6': 'LABEL_6', '7': 'LABEL_7', '8': 'LABEL_8', '9': 'LABEL_9', '10': 'LABEL_10', '11': 'LABEL_11'}. The number of labels wil be overwritten to 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter comments. Type 'done' when you're finished.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a comment:  i love this hospital and the staff was very friendly\n",
      "Enter a comment:  i dont linke the food as it was not that fresh\n",
      "Enter a comment:  every think was good except, i want more beds in the icu \n",
      "Enter a comment:  done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorizing Feedback: 100%|█████████████████████████████████████████████████████████| 348/348 [00:38<00:00,  9.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:43<00:00,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization and Sentiment analysis complete! Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load the multi-label classification model and tokenizer\n",
    "model_clf = AutoModelForSequenceClassification.from_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\fine_tuned_bart_model')\n",
    "tokenizer_clf = AutoTokenizer.from_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\fine_tuned_bart_model')\n",
    "\n",
    "# Load the sentiment analysis model and tokenizer\n",
    "tokenizer_senti = AutoTokenizer.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)\")\n",
    "model_senti = AutoModelForSequenceClassification.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)\")\n",
    "\n",
    "# Move models to device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_clf.to(device)\n",
    "model_senti.to(device)\n",
    "\n",
    "# Load the Excel file with feedback data\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data.xlsx')\n",
    "\n",
    "# Candidate labels for multi-label classification\n",
    "candidate_labels = [\n",
    "    \"Service Quality\", \"Doctor Experience\", \"Nursing Experience\",\n",
    "    \"Interaction with Staff\", \"Lab & Radiology Services\", \"Facilities and Infrastructure\",\n",
    "    \"Billing and Payments\", \"Appointment Process\", \"Admission & Discharge\",\n",
    "    \"Food & Beverages\", \"Housekeeping/PCA/PTA\", \"Others\"\n",
    "]\n",
    "\n",
    "# Function for multi-label classification (categorization)\n",
    "def preprocess_text(text, tokenizer, max_length=128):\n",
    "    return tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "def predict_category_pt(text, model, tokenizer, candidate_labels, threshold=0.5):\n",
    "    inputs = preprocess_text(text, tokenizer)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    predicted_labels = (probabilities > threshold).int().squeeze().tolist()\n",
    "    \n",
    "    predicted_categories = [candidate_labels[i] for i in range(len(candidate_labels)) if predicted_labels[i] == 1]\n",
    "    \n",
    "    return predicted_categories, probabilities.squeeze().tolist()\n",
    "\n",
    "def categorize_feedback_pt(df, model, tokenizer, candidate_labels, threshold=0.2):\n",
    "    all_predictions = []\n",
    "    all_probabilities = {label: [] for label in candidate_labels}\n",
    "    \n",
    "    for comment in tqdm(df['feedback'], desc=\"Categorizing Feedback\"):\n",
    "        predicted_categories, probabilities = predict_category_pt(comment, model, tokenizer, candidate_labels, threshold)\n",
    "        all_predictions.append(predicted_categories)\n",
    "        \n",
    "        for i, label in enumerate(candidate_labels):\n",
    "            all_probabilities[label].append(probabilities[i])\n",
    "    \n",
    "    df['Categories'] = all_predictions\n",
    "    for label in candidate_labels:\n",
    "        df[f'{label}_score'] = all_probabilities[label]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def analyze_sentiment_batch(comments_batch):\n",
    "    comments_batch = [str(comment) if not isinstance(comment, str) else comment for comment in comments_batch]\n",
    "    encoded_text = tokenizer_senti(\n",
    "        comments_batch,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    encoded_text = {key: value.to(device) for key, value in encoded_text.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_senti(**encoded_text)\n",
    "\n",
    "    scores = output[0].detach().cpu().numpy()\n",
    "    scores = softmax(scores, axis=-1)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def process_in_batches(df, batch_size=64):\n",
    "    all_scores = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_comments = df['feedback'].iloc[i:i+batch_size].fillna('').astype(str).values\n",
    "        scores = analyze_sentiment_batch(batch_comments)\n",
    "        all_scores.append(scores)\n",
    "\n",
    "    return np.vstack(all_scores)\n",
    "\n",
    "# Function to add new comments to the DataFrame\n",
    "def add_new_comments_to_df(df, new_comments):\n",
    "    new_comments_df = pd.DataFrame(new_comments, columns=['feedback'])\n",
    "    df = pd.concat([df, new_comments_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# Function to get comments from the terminal\n",
    "def get_comments_from_terminal():\n",
    "    new_comments = []\n",
    "    print(\"Enter comments. Type 'done' when you're finished.\")\n",
    "    \n",
    "    while True:\n",
    "        comment = input(\"Enter a comment: \")\n",
    "        if comment.lower() == 'done':\n",
    "            break\n",
    "        else:\n",
    "            new_comments.append(comment)\n",
    "    \n",
    "    return new_comments\n",
    "\n",
    "# Get new comments from the user via the terminal\n",
    "new_comments = get_comments_from_terminal()\n",
    "\n",
    "# Add new comments to the DataFrame\n",
    "df = add_new_comments_to_df(df, new_comments)\n",
    "\n",
    "# Process multi-label classification (categorization)\n",
    "df = categorize_feedback_pt(df, model_clf, tokenizer_clf, candidate_labels)\n",
    "\n",
    "# Process sentiment analysis\n",
    "scores = process_in_batches(df)\n",
    "\n",
    "# Convert sentiment scores to DataFrame columns\n",
    "df['roberta_neg'] = scores[:, 0]\n",
    "df['roberta_neu'] = scores[:, 1]\n",
    "df['roberta_pos'] = scores[:, 2]\n",
    "\n",
    "# Assign final sentiment based on highest score\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "df['Sentiment ROBERTA'] = [sentiment_labels[np.argmax(scores)] for scores in df[['roberta_neg', 'roberta_neu', 'roberta_pos']].values]\n",
    "\n",
    "# Save results to a new Excel file\n",
    "df.to_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data(CAT & SENTI).xlsx', index=False)\n",
    "\n",
    "print(\"Categorization and Sentiment analysis complete! Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26992dc-05e9-43f8-ab7b-3a515a64e51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senti",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
