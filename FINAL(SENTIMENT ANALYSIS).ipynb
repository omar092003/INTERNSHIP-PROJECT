{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a59670-c73d-4610-96de-36562f3e3dc7",
   "metadata": {},
   "source": [
    "# EDA FOR SENTIMENT ANANLYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d202ecb0-5a84-482e-87d8-d796c6e883d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "186f385f-66d0-410e-af08-bba601bb4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ace3363c-c007-456f-a64f-963b6f196355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feedback_comments', 'Sentiment', 'Unnamed: 2'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107bd91d-7132-4ed5-9c9f-19c1ea453969",
   "metadata": {},
   "source": [
    "# TRANSLATION AND CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2df632a0-b08f-477d-a839-7adf42ba6df3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to detect or translate text: servis very good\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: nice\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: yaar  lakh cash deposit he  lakh ki policy sab pura kar diya\n",
      "Unable to detect or translate text: excellent services\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: excellent service by all concern departments\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: excellent service by all concern departments\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: good service\n",
      "Unable to detect or translate text: friendly staff\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: excellent service\n",
      "Unable to detect or translate text: excellent keep doing best\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: overall excellent  experience\n",
      "Unable to detect or translate text: requirement for extra doctors  for radiology deptusgdept\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: grt experience\n",
      "Unable to detect or translate text: good service keep it up\n",
      "Unable to detect or translate text: great experience\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: excellent experience\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: great work keep it up\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: good work\n",
      "Unable to detect or translate text: well done  good care taken\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: nice services\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: test\n",
      "Unable to detect or translate text: no comment\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: efficient clear professional experience gives confidence to patient and encourage return\n",
      "Unable to detect or translate text: best service given\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: very nice\n",
      "Unable to detect or translate text: good service\n",
      "Unable to detect or translate text: excellent hospitality\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: long waiting times\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: a small fan at tmt mill\n",
      "Unable to detect or translate text: very nice invorment  keep it up\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: v good\n",
      "Unable to detect or translate text: great staff  just like family\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: all excellent good service\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: impressive services\n",
      "Unable to detect or translate text: excellent service\n",
      "Unable to detect or translate text: friendly\n",
      "Unable to detect or translate text: nice service\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: female  gynac\n",
      "Unable to detect or translate text: not required\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: good  service\n",
      "Unable to detect or translate text: super experience\n",
      "Unable to detect or translate text: ok\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: i loved it keep it up\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: all are good\n",
      "Unable to detect or translate text: outstanding\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: impressed\n",
      "Unable to detect or translate text: superb\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: excellent xperience\n",
      "Unable to detect or translate text: excellent experience\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: keep smilling\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no any\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: great experience\n",
      "Unable to detect or translate text: ok\n",
      "Unable to detect or translate text: great experience  keep it up\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: super\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: excellent services in hospital\n",
      "Unable to detect or translate text: good work very helpfull\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: all good keep it up\n",
      "Unable to detect or translate text: good arrangements\n",
      "Unable to detect or translate text: excellent keep it up\n",
      "Unable to detect or translate text: excellent services\n",
      "Unable to detect or translate text: excellent courtesy\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: excellent care taken\n",
      "Unable to detect or translate text: a great picinc bonanza\n",
      "Unable to detect or translate text: all was good\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: excellent services\n",
      "Unable to detect or translate text: good friendly staff\n",
      "Unable to detect or translate text: excellent services\n",
      "Unable to detect or translate text: good friendly staff\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: very good\n",
      "Unable to detect or translate text: very good\n",
      "Unable to detect or translate text: excellent  service\n",
      "Unable to detect or translate text: excellent services and support\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: over all superb experience\n",
      "Unable to detect or translate text: include ent and dentistry\n",
      "Unable to detect or translate text: v nice\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: keep the good work going\n",
      "Unable to detect or translate text: its ok\n",
      "Unable to detect or translate text: excellent\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: we r happy\n",
      "Unable to detect or translate text: nice exp\n",
      "Unable to detect or translate text: na\n",
      "Unable to detect or translate text: great work  keep it up\n",
      "Unable to detect or translate text: great work keep it up\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: no\n",
      "Unable to detect or translate text: none\n",
      "Unable to detect or translate text: keep it up\n",
      "Unable to detect or translate text: nil\n",
      "Unable to detect or translate text: keep going better than ever\n",
      "Unable to detect or translate text: good\n",
      "Unable to detect or translate text: too good\n",
      "Unable to detect or translate text: great work keep it up\n",
      "Translated the comments and updated the 'feedback_comments' column.\n",
      "Updated DataFrame has been saved to C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from googletrans import Translator\n",
    "from langdetect import detect\n",
    "\n",
    "# Define the text preprocessing function\n",
    "def preprocessing_text(text):\n",
    "    \"\"\"Remove extra spaces, tabs, newlines, special characters, and emojis.\"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "    text = text.lower()\n",
    "    text = text.strip()  # Remove leading/trailing whitespaces\n",
    "    text = text.replace(\"\\t\", \"\").replace(\"\\n\", \"\")  # Remove tabs and newlines\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetical characters (except spaces)\n",
    "    text = emoji.replace_emoji(text, replace='')  # Remove emojis\n",
    "     # Remove any adjacent special characters that are attached to words without space\n",
    "    text = re.sub(r'([a-zA-Z])([^\\w\\s])', r'\\1', text)  # Remove punctuation after a letter (like `word!` -> `word`)\n",
    "    text = re.sub(r'([^\\w\\s])([a-zA-Z])', r'\\2', text)  # Remove punctuation before a letter (like `,hello` -> `hello`)\n",
    "    return text\n",
    "\n",
    "# Initialize Google Translate API (Translator)\n",
    "translator = Translator()\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    \"\"\"Detect the language of the provided text.\"\"\"\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang == 'hi':\n",
    "            return \"Hindi\"\n",
    "        elif lang == 'en':\n",
    "            return \"English\"\n",
    "        else:\n",
    "            return lang  # Return the detected language instead of \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in language detection: {e}\")\n",
    "        return \"Error in detection\"\n",
    "\n",
    "# Function to handle translation (only if Hindi)\n",
    "def translate_text_if_needed(text):\n",
    "    \"\"\"Detect the language and translate if the text is in Hindi.\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return text  # Return as-is if the text is empty or NaN\n",
    "    \n",
    "    # Preprocess the text before language detection and translation\n",
    "    preprocessed_text = preprocessing_text(text)\n",
    "    \n",
    "    # Detect language of the preprocessed comment\n",
    "    language = detect_language(preprocessed_text)\n",
    "\n",
    "    if language == \"Hindi\":\n",
    "        try:\n",
    "            # Translate from Hindi to English\n",
    "            translated_text = translator.translate(preprocessed_text, src='hi', dest='en').text\n",
    "            print(f\"Original text (Hindi): {preprocessed_text}\")\n",
    "            print(f\"Translated text: {translated_text}\")\n",
    "            return translated_text  # Return the translated text\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation: {e}\")\n",
    "            return preprocessed_text  # Return the original text in case of an error\n",
    "    elif language == \"English\":\n",
    "        # If already in English, return the preprocessed text\n",
    "        return preprocessed_text\n",
    "    else:\n",
    "        # Handle unknown or error cases\n",
    "        print(f\"Unable to detect or translate text: {preprocessed_text}\")\n",
    "        return preprocessed_text  # Return as-is if the language is neither Hindi nor English\n",
    "\n",
    "# Load your DataFrame from the provided CSV file\n",
    "try:\n",
    "    df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx')  # Update the path if necessary\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the CSV file: {e}\")\n",
    "    exit()  # Exit if file reading fails\n",
    "\n",
    "# Ensure that the 'feedback_comments' column exists in the DataFrame\n",
    "if 'feedback_comments' not in df.columns:\n",
    "    print(\"The 'feedback_comments' column is not found in the DataFrame. Please check the column name.\")\n",
    "else:\n",
    "    # Drop rows where 'feedback_comments' column has missing values\n",
    "    df = df.dropna(subset=[\"feedback_comments\"])\n",
    "    \n",
    "    # Iterate through the 'feedback_comments' column, preprocess, detect language, translate if needed, and update the DataFrame\n",
    "    for idx, comment in enumerate(df[\"feedback_comments\"]):\n",
    "        translated_comment = translate_text_if_needed(comment)\n",
    "        # Update the DataFrame directly with the translated comment\n",
    "        df.at[idx, \"feedback_comments\"] = translated_comment\n",
    "\n",
    "    # Print confirmation message\n",
    "    print(f\"Translated the comments and updated the 'feedback_comments' column.\")\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file (overwrite the original)\n",
    "    output_file = r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx'  # Update the output path if necessary\n",
    "    try:\n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Updated DataFrame has been saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bbc2957-513d-4c4b-be1e-3368cba10876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['feedback_comments', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "428217c6-f5c8-4ce6-a686-9742daba8417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feedback_comments', 'Sentiment', 'Unnamed: 2'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85bad66d-0fd5-485a-937b-d7e684ed8992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame has been saved to C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file (overwrite the original)\n",
    "output_file = r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx'  # Update the output path if necessary\n",
    "try:\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Updated DataFrame has been saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d7730ab-6127-4dab-8c81-aa9f7bc5deca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feedback_comments', 'Sentiment', 'Unnamed: 2'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74fe36e-0a04-43f7-9c61-60c9f63fa896",
   "metadata": {},
   "source": [
    "# PREPARE LABEL DATA FOR FINE TUNEING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dab56572-17ce-49ee-8b34-5cf24d42fafb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  sentiment_label\n",
      "0  Negative                0\n",
      "1  Positive                2\n",
      "2   Neutral                1\n",
      "3  Positive                2\n",
      "4  Positive                2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame from Excel file\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx')\n",
    "\n",
    "# Check if there are any missing values in 'Sentiment' column and drop them\n",
    "df.dropna(subset=['Sentiment'], inplace=True)\n",
    "\n",
    "# Mapping sentiment labels to integers\n",
    "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "\n",
    "# Create a new column 'sentiment_label' by mapping the 'Sentiment' column\n",
    "df['sentiment_label'] = df['Sentiment'].map(label_map)\n",
    "\n",
    "# Check the first few rows to ensure the new column is created correctly\n",
    "print(df[['Sentiment', 'sentiment_label']].head())\n",
    "\n",
    "# Save the updated dataframe to a new Excel file if needed\n",
    "df.to_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3dca8-0022-45f9-b5bc-b5f1ce1c54d0",
   "metadata": {},
   "source": [
    "# FINE TUNE A PRETRAINED MODEL (ROBERTA-BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735506dc-4170-4065-9aec-42e7de2803e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "####TO FINETUNE THE MODEL YOU NEED THREE COLUMNS IN EXCEL SHEET(FEEDBACK=COMMENTS),(SENTIMENT=POS,NEG,NEU)AND(SENTIMET_LABEL=0,1,2)\n",
    "####MAKE SURE -(NEG=0,NEU=1,POS=2)#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d489c699-d685-43d7-8f06-85bf91b444f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumeet4.singh\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_roberta(BASE) and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\sumeet4.singh\\AppData\\Local\\miniconda3\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582 65 582 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████| 73/73 [05:53<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1: 0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2418\n",
      "Validation Accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|███████████████████████████████████████████████████████████████████████| 73/73 [05:49<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2: 0.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1948\n",
      "Validation Accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████| 73/73 [05:51<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 3: 0.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1957\n",
      "Validation Accuracy: 0.9385\n",
      "Model fine-tuned and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Load your DataFrame from Excel file\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(SENTI).xlsx')\n",
    "\n",
    "# Ensure there are no missing values in 'feedback_comments' or 'Sentiment'\n",
    "df.dropna(subset=['feedback_comments', 'Sentiment'], inplace=True)\n",
    "\n",
    "# Mapping sentiment labels to integers (assuming 3 classes: Negative, Neutral, Positive)\n",
    "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "df['sentiment_label'] = df['Sentiment'].map(label_map)\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_roberta(BASE)\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_roberta(BASE)\", num_labels=3)\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the 'feedback_comments' column\n",
    "tokenized_inputs = tokenizer(df['feedback_comments'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert labels to a tensor\n",
    "labels = torch.tensor(df['sentiment_label'].values)\n",
    "\n",
    "# Check if the number of tokens matches the number of samples in the DataFrame\n",
    "assert len(df) == len(tokenized_inputs['input_ids']), \"Mismatch in number of samples!\"\n",
    "assert len(df) == len(labels), \"Mismatch in number of samples!\"\n",
    "\n",
    "# Split into train and validation sets (90% train, 10% validation)\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    tokenized_inputs['input_ids'], labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Check the lengths of train/test sets\n",
    "print(len(train_inputs), len(val_inputs), len(train_labels), len(val_labels))\n",
    "\n",
    "# Convert tokenized inputs to PyTorch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "\n",
    "# Ensure that attention masks are also correctly split and converted to tensors\n",
    "train_attention_mask = torch.tensor(tokenized_inputs['attention_mask'][:len(train_inputs)])\n",
    "val_attention_mask = torch.tensor(tokenized_inputs['attention_mask'][:len(val_inputs)])\n",
    "\n",
    "# Create TensorDatasets for training and validation\n",
    "train_dataset = TensorDataset(train_inputs, train_attention_mask, train_labels)\n",
    "val_dataset = TensorDataset(val_inputs, val_attention_mask, val_labels)\n",
    "\n",
    "# Create DataLoaders for batch processing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Iterate through the training data\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        # Move batch to GPU\n",
    "        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute the average loss for this epoch\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss for epoch {epoch+1}: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_eval_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)')\n",
    "tokenizer.save_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)')\n",
    "\n",
    "print(\"Model fine-tuned and saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a364f-919a-4d14-8252-3e665c16af5e",
   "metadata": {},
   "source": [
    "# USE THE FINE TUNED MODEL (ROBERTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aaf1737-d84a-4e23-896c-f5dbb06f1b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feedback'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5082555d-d7bd-48d2-9076-fb3a2b84c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:44<00:00,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete! Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data.xlsx')\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')\n",
    "\n",
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\finetuned_trained_roberta(BASE)\")\n",
    "\n",
    "# Move model to the GPU\n",
    "# model.to(device)\n",
    "\n",
    "# Function to batch process sentiment analysis\n",
    "def analyze_sentiment_batch(comments_batch):\n",
    "    # Ensure all comments are strings, handling NaN or invalid entries\n",
    "    comments_batch = [str(comment) if not isinstance(comment, str) else comment for comment in comments_batch]\n",
    "\n",
    "    # Tokenize the batch of comments\n",
    "    encoded_text = tokenizer(\n",
    "        comments_batch,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Move the inputs to GPU\n",
    "    encoded_text = {key: value.to(device) for key, value in encoded_text.items()}\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():  # Turn off gradient calculations for inference\n",
    "        output = model(**encoded_text)\n",
    "\n",
    "    # Get sentiment scores from the model output\n",
    "    scores = output[0].detach().cpu().numpy()  # Move the result back to CPU\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    scores = softmax(scores, axis=-1)  # Apply softmax across the logits\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Function to process the data in batches\n",
    "def process_in_batches(df, batch_size=64):\n",
    "    all_scores = []\n",
    "\n",
    "    # Batch process the data\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        # Ensure all comments are strings and handle NaN values\n",
    "        batch_comments = df['feedback'].iloc[i:i+batch_size].fillna('').astype(str).values\n",
    "\n",
    "        scores = analyze_sentiment_batch(batch_comments)\n",
    "\n",
    "        # Store results\n",
    "        all_scores.append(scores)\n",
    "\n",
    "    # Flatten the list of arrays and return\n",
    "    return np.vstack(all_scores)\n",
    "\n",
    "# Process the entire DataFrame in batches\n",
    "scores = process_in_batches(df)\n",
    "\n",
    "# Convert scores to a DataFrame and assign labels\n",
    "df['roberta_neg'] = scores[:, 0]\n",
    "df['roberta_neu'] = scores[:, 1]\n",
    "df['roberta_pos'] = scores[:, 2]\n",
    "\n",
    "# Assign final sentiment based on the highest score\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "df['Sentiment ROBERTA'] = [sentiment_labels[np.argmax(scores)] for scores in df[['roberta_neg', 'roberta_neu', 'roberta_pos']].values]\n",
    "\n",
    "# Save results to Excel\n",
    "df.to_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data(SENTI).xlsx', index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete! Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7cb6b-0b16-4dea-877c-2fe7b3d283d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senti",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
