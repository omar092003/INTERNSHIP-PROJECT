{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aba6c82-0473-45bb-95e1-47cee9e87c0c",
   "metadata": {},
   "source": [
    "# BINARY FORMATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74dd7af-ce18-4055-9977-7074f2951063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0725f00-0bab-4d34-8d36-eb45af4b594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(CAT).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9435ab-380e-424c-b086-7c323d3ece37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of                                      feedback_comments  \\\n",
       "0    doctors should be here on time..  I had to wai...   \n",
       "1    long waiting for dietitian and doctors consult...   \n",
       "2    consulting not done in time so couldn't  compl...   \n",
       "3    there was carelessness while attending the pat...   \n",
       "4                   Excellent team at Executive health   \n",
       "..                                                 ...   \n",
       "245  Discharge instructions were clear and well exp...   \n",
       "246    Admission staff were professional and efficient   \n",
       "247    The discharge process took longer than expected   \n",
       "248  I was well informed about the steps during my ...   \n",
       "249  The staff was helpful during admission, and th...   \n",
       "\n",
       "                                    Categories  \n",
       "0                            Doctor Experience  \n",
       "1    Interaction with Staff, Doctor Experience  \n",
       "2                              Service Quality  \n",
       "3                              Service Quality  \n",
       "4                       Interaction with Staff  \n",
       "..                                         ...  \n",
       "245                      Admission & Discharge  \n",
       "246                      Admission & Discharge  \n",
       "247                      Admission & Discharge  \n",
       "248                      Admission & Discharge  \n",
       "249              Admission & Discharge, Others  \n",
       "\n",
       "[250 rows x 2 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f362e7ed-b45a-4fdd-964c-ea11f6887d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feedback_comments', 'Categories'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00b0fb0-93da-4d58-9e8f-78b0b7d42b3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   feedback_comments  \\\n",
      "0  doctors should be here on time..  I had to wai...   \n",
      "1  long waiting for dietitian and doctors consult...   \n",
      "2  consulting not done in time so couldn't  compl...   \n",
      "3  there was carelessness while attending the pat...   \n",
      "4                 Excellent team at Executive health   \n",
      "\n",
      "                                  Categories  Service Quality  \\\n",
      "0                          Doctor Experience                0   \n",
      "1  Interaction with Staff, Doctor Experience                0   \n",
      "2                            Service Quality                1   \n",
      "3                            Service Quality                1   \n",
      "4                     Interaction with Staff                0   \n",
      "\n",
      "   Doctor Experience  Nursing Experience  Interaction with Staff  \\\n",
      "0                  1                   0                       0   \n",
      "1                  1                   0                       1   \n",
      "2                  0                   0                       0   \n",
      "3                  0                   0                       0   \n",
      "4                  0                   0                       1   \n",
      "\n",
      "   Lab & Radiology Services  Facilities and Infrastructure  \\\n",
      "0                         0                              0   \n",
      "1                         0                              0   \n",
      "2                         0                              0   \n",
      "3                         0                              0   \n",
      "4                         0                              0   \n",
      "\n",
      "   Billing and Payments  Appointment Process  Admission & Discharge  \\\n",
      "0                     0                    0                      0   \n",
      "1                     0                    0                      0   \n",
      "2                     0                    0                      0   \n",
      "3                     0                    0                      0   \n",
      "4                     0                    0                      0   \n",
      "\n",
      "   Food & Beverages  Housekeeping/PCA/PTA  Others  \n",
      "0                 0                     0       0  \n",
      "1                 0                     0       0  \n",
      "2                 0                     0       0  \n",
      "3                 0                     0       0  \n",
      "4                 0                     0       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the provided Excel file\n",
    "file_path = r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(CAT).xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# List of candidate labels (categories you want to create binary columns for)\n",
    "candidate_labels = [\n",
    "    \"Service Quality\", \"Doctor Experience\", \"Nursing Experience\",\n",
    "    \"Interaction with Staff\", \"Lab & Radiology Services\", \"Facilities and Infrastructure\",\n",
    "    \"Billing and Payments\", \"Appointment Process\", \"Admission & Discharge\",\n",
    "    \"Food & Beverages\", \"Housekeeping/PCA/PTA\", \"Others\"\n",
    "]\n",
    "\n",
    "# Function to create binary columns based on the categories column\n",
    "def create_binary_columns(df, candidate_labels):\n",
    "    for label in candidate_labels:\n",
    "        # Create a new column for each category\n",
    "        df[label] = df['Categories'].apply(lambda x: 1 if label in str(x) else 0)\n",
    "    return df\n",
    "\n",
    "# Apply the function to add binary columns to the dataframe\n",
    "df = create_binary_columns(df, candidate_labels)\n",
    "\n",
    "# Save the updated DataFrame with the binary columns to a new Excel file\n",
    "output_path = r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(BINARY).xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "# Display the resulting DataFrame to check\n",
    "print(df.head())  # Display the first few rows of the updated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e267c8a-6a71-4b68-b77e-ad1d32be2326",
   "metadata": {},
   "source": [
    "# NOW FINE TUNE FOR CATEGORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de537f56-4e65-4271-85b2-1d5adff8fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a612cd-0d5c-40cc-9d20-4d997f7affca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from the provided Excel file\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\TRAIN(BINARY).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436d6cd4-12e8-4c9a-bf29-ec39786b1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample candidate labels for categorization (as per your list)\n",
    "candidate_labels = [\n",
    "    \"Service Quality\", \"Doctor Experience\", \"Nursing Experience\",\n",
    "    \"Interaction with Staff\", \"Lab & Radiology Services\", \"Facilities and Infrastructure\",\n",
    "    \"Billing and Payments\", \"Appointment Process\", \"Admission & Discharge\",\n",
    "    \"Food & Beverages\", \"Housekeeping/PCA/PTA\", \"Others\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5f7ead-7d60-4761-9953-5f7fddfde9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'feedback_comments' column is in string format\n",
    "df['feedback_comments'] = df['feedback_comments'].astype(str)\n",
    "\n",
    "# Replace 'nan' (as a string) with an empty string (or another placeholder like 'No comment')\n",
    "df['feedback_comments'] = df['feedback_comments'].replace('nan', '').replace('No comment', '').replace('  ', ' ')\n",
    "\n",
    "# Function to clean and prepare the comment text\n",
    "def clean_comment(comment):\n",
    "    # Remove leading/trailing spaces and newlines\n",
    "    comment = comment.strip()\n",
    "    # Normalize multiple spaces to a single space\n",
    "    comment = re.sub(r'\\s+', ' ', comment)\n",
    "    # Remove any non-ASCII characters (if needed)\n",
    "    comment = ''.join([c for c in comment if ord(c) < 128])\n",
    "    return comment\n",
    "\n",
    "# Apply cleaning function to all comments\n",
    "df['feedback_comments'] = df['feedback_comments'].apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a0fac70-7d3b-43a1-8aef-f197c28bfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the binary labels (12 columns for each category)\n",
    "labels_columns = candidate_labels  # These columns contain binary labels\n",
    "\n",
    "# Directly use the binary labels from the DataFrame\n",
    "df_labels = df[labels_columns].values  # This is already in binary format for each category\n",
    "\n",
    "# Function to preprocess text using the BART tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_BART\")\n",
    "\n",
    "def preprocess_data(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['feedback_comments'].tolist(), df_labels.tolist(), test_size=0.2)\n",
    "\n",
    "train_inputs = preprocess_data(train_texts, tokenizer)\n",
    "val_inputs = preprocess_data(val_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78b493aa-0e72-47c1-867b-be1e07f18286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch datasets\n",
    "class FeedbackDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.input_ids = inputs['input_ids']\n",
    "        self.attention_mask = inputs['attention_mask']\n",
    "        # Convert labels to Float type here (for multi-label classification)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = FeedbackDataset(train_inputs, train_labels)\n",
    "val_dataset = FeedbackDataset(val_inputs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51e06d34-bffd-4d6c-bd4c-90b4f6140c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_BART and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BART model for sequence classification (multi-label classification)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\pre_trained_BART',\n",
    "    num_labels=len(candidate_labels),\n",
    "    problem_type=\"multi_label_classification\"  # Explicitly specify multi-label classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f06518b-142f-409a-9621-983c3a90ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumeet4.singh\\AppData\\Local\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\sumeet4.singh\\AppData\\Local\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:1583: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  # Adjust epochs based on your needs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True  # Explicitly disable CUDA (GPU) usage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b3887ec-1b66-40eb-8a55-8eb9f553d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumeet4.singh\\AppData\\Local\\Temp\\ipykernel_4072\\107209988.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 08:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.342350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.338741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.328245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=0.27484471003214517, metrics={'train_runtime': 530.3433, 'train_samples_per_second': 1.131, 'train_steps_per_second': 0.141, 'total_flos': 163022168678400.0, 'train_loss': 0.27484471003214517, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b99a4c1-8d55-4dd0-be48-d11de0963395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model and tokenizer saved!\n"
     ]
    }
   ],
   "source": [
    "# Directory where the model and tokenizer will be saved\n",
    "save_dir = r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\fine_tuned_bart_model'\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(save_dir)\n",
    "\n",
    "# Save the tokenizer to the same directory\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Fine-tuning complete. Model and tokenizer saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4e173-a791-408e-9b3f-d1ffd01636ea",
   "metadata": {},
   "source": [
    "# USE THE FINE TUNE MODEL NOW ON (BENCHMARKING DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a12230e7-df24-4e3b-bed1-95621e816934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2', '3': 'LABEL_3', '4': 'LABEL_4', '5': 'LABEL_5', '6': 'LABEL_6', '7': 'LABEL_7', '8': 'LABEL_8', '9': 'LABEL_9', '10': 'LABEL_10', '11': 'LABEL_11'}. The number of labels wil be overwritten to 12.\n",
      "Categorizing Feedback: 100%|█████████████████████████████████████████████████████████| 345/345 [00:37<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization complete with scores. Results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the fine-tuned PyTorch model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\fine_tuned_bart_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Scripts\\fine_tuned_bart_model')\n",
    "\n",
    "# Move model to device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data.xlsx')\n",
    "\n",
    "# Sample candidate labels for categorization\n",
    "candidate_labels = [\n",
    "    \"Service Quality\", \"Doctor Experience\", \"Nursing Experience\",\n",
    "    \"Interaction with Staff\", \"Lab & Radiology Services\", \"Facilities and Infrastructure\",\n",
    "    \"Billing and Payments\", \"Appointment Process\", \"Admission & Discharge\",\n",
    "    \"Food & Beverages\", \"Housekeeping/PCA/PTA\", \"Others\"\n",
    "]\n",
    "\n",
    "# Function to preprocess the text (same as the one used during training)\n",
    "def preprocess_text(text, tokenizer, max_length=128):\n",
    "    return tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "# Function to make predictions for a single comment (PyTorch version)\n",
    "def predict_category_pt(text, model, tokenizer, candidate_labels, threshold=0.5):\n",
    "    # Preprocess the input text\n",
    "    inputs = preprocess_text(text, tokenizer)\n",
    "    \n",
    "    # Move the input tensors to the same device as the model (GPU or CPU)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Ensure that the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make predictions (output is logits)\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted logits and apply a sigmoid to get probabilities\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.sigmoid(logits)  # Apply sigmoid for multi-label classification\n",
    "    \n",
    "    # Convert probabilities to labels (1 for categories with probability > threshold, else 0)\n",
    "    predicted_labels = (probabilities > threshold).int().squeeze().tolist()\n",
    "    \n",
    "    # Map the predictions to the corresponding categories\n",
    "    predicted_categories = [candidate_labels[i] for i in range(len(candidate_labels)) if predicted_labels[i] == 1]\n",
    "    \n",
    "    return predicted_categories, probabilities.squeeze().tolist()\n",
    "\n",
    "# Function to categorize all feedback comments in the DataFrame\n",
    "def categorize_feedback_pt(df, model, tokenizer, candidate_labels, threshold=0.2):\n",
    "    all_predictions = []\n",
    "    all_probabilities = {label: [] for label in candidate_labels}\n",
    "    \n",
    "    for comment in tqdm(df['feedback'], desc=\"Categorizing Feedback\"):  # Assuming column name is 'feedback_comments'\n",
    "        predicted_categories, probabilities = predict_category_pt(comment, model, tokenizer, candidate_labels, threshold)\n",
    "        all_predictions.append(predicted_categories)\n",
    "        \n",
    "        for i, label in enumerate(candidate_labels):\n",
    "            all_probabilities[label].append(probabilities[i])\n",
    "    \n",
    "    df['Categories'] = all_predictions\n",
    "    for label in candidate_labels:\n",
    "        df[f'{label}_score'] = all_probabilities[label]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ensure 'feedback_comments' column exists in the DataFrame\n",
    "if 'feedback' in df.columns:\n",
    "    df = categorize_feedback_pt(df, model, tokenizer, candidate_labels)\n",
    "else:\n",
    "    print(\"Error: The DataFrame does not contain a 'feedback' column\")\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "df.to_excel(r'C:\\Users\\sumeet4.singh\\Desktop\\senti_project\\1. Feedback_Project\\Data\\Benchmarking data(CAT).xlsx', index=False)\n",
    "\n",
    "print(\"Categorization complete with scores. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdb6dd-9632-45e6-a2d0-c8272cbc6998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senti",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
